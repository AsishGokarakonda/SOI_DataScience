{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "soi_nn_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Creating and Training the Model"
      ],
      "metadata": {
        "id": "1UlSIw3Maxug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Cleaning and Transformation"
      ],
      "metadata": {
        "id": "goRoKJkOiQ4a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EAHVuHjre3WI"
      },
      "outputs": [],
      "source": [
        "#Load data\n",
        "import pandas as pd\n",
        "import random\n",
        "data = pd.read_csv('problem_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the blank columns and unnecessary columns\n",
        "data.drop('tce_rogue_flag', inplace=True, axis=1)\n",
        "data.drop('tce_insol', inplace=True, axis=1)\n",
        "data.drop('tce_insol_err', inplace=True, axis=1)\n",
        "data.drop('kepid', inplace=True, axis=1)\n",
        "\n",
        "# Last column is labels(i.e. y), and rest are features(i.e. x)\n",
        "# Shuffle data before partitioning\n",
        "\n",
        "\n",
        "data = data.sample(frac=1) \n",
        "y = data['av_training_set']\n",
        "x = data.drop('av_training_set', axis=1)\n",
        "\n",
        "print(y)\n",
        "\n",
        "# Partition dataset into training part and testing part\n",
        "x_train = x\n",
        "y_train = y\n",
        "\n"
      ],
      "metadata": {
        "id": "eZQ1gKMKe9iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def string_to_onehot(arr):  # Convert text labels to one-hot encoding for categorical classification\n",
        "  int_arr = []\n",
        "\n",
        "  for x in arr:\n",
        "    if x=='AFP':\n",
        "      int_arr.append([1,0,0,0])\n",
        "    \n",
        "    elif x=='NTP':\n",
        "      int_arr.append([0,1,0,0])\n",
        "    \n",
        "    elif x=='PC':\n",
        "      int_arr.append([0,0,1,0])\n",
        "      \n",
        "    elif x=='UNK':\n",
        "      int_arr.append([0,0,0,1])\n",
        "  \n",
        "  return int_arr\n",
        "\n",
        "  \n",
        "def onehot_to_string(int_arr):  # Convert back one-hot to text\n",
        "  res = []\n",
        "\n",
        "  for x in int_arr:\n",
        "    if max(x) == x[0]:\n",
        "      res.append('AFP')\n",
        "    elif max(x) == x[1]:\n",
        "      res.append('NTP')\n",
        "    elif max(x) == x[2]:\n",
        "      res.append('PC')\n",
        "    elif max(x) == x[3]:\n",
        "      res.append('UNK')\n",
        "  return res"
      ],
      "metadata": {
        "id": "-1tFb5TIx7z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = pd.DataFrame(string_to_onehot(y_train))\n",
        "print(y_train)"
      ],
      "metadata": {
        "id": "ndyPymUXXraM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "LXvU5Ev1j080"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(y_train)"
      ],
      "metadata": {
        "id": "4nJj8nVUyv8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating the Model"
      ],
      "metadata": {
        "id": "VU0dBUKaibFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model = Sequential()\n",
        "import tensorflow as tf\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_dim=22))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "SChCEY91fOFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training the Model"
      ],
      "metadata": {
        "id": "M_5aEJDFihiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss = 'categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bgGmXb_rP7GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train, y_train, epochs=1000, batch_size=500)"
      ],
      "metadata": {
        "id": "D1bWl9hofeLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p saved_model"
      ],
      "metadata": {
        "id": "g6Fdp2BbPti2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model')"
      ],
      "metadata": {
        "id": "T1rLmVhAP1bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r model model\n",
        "# Download the model from the colab files"
      ],
      "metadata": {
        "id": "qohMlLGUQMGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# convert the training history to a dataframe\n",
        "history_df = pd.DataFrame(hist.history)\n",
        "# use Pandas native plot method to plot loss vs epochs\n",
        "history_df['loss'].plot();"
      ],
      "metadata": {
        "id": "fRL6W7qQeINz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing the model"
      ],
      "metadata": {
        "id": "7hPGRigviqMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_data = pd.read_csv('sample_input.csv')"
      ],
      "metadata": {
        "id": "FKf-bRcke6uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the blank columns and unnecessary columns\n",
        "test_data.drop('tce_rogue_flag', inplace=True, axis=1)\n",
        "test_data.drop('tce_insol', inplace=True, axis=1)\n",
        "test_data.drop('tce_insol_err', inplace=True, axis=1)\n",
        "test_data.drop('kepid', inplace=True, axis=1)\n",
        "\n",
        "x_test = test_data\n",
        "\n",
        "print(x_test)\n"
      ],
      "metadata": {
        "id": "BJPl8yMjhfyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "jREzKZtnfir9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred.tolist()\n",
        "y_pred = onehot_to_string(y_pred)"
      ],
      "metadata": {
        "id": "EZY2RznWlXeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred)"
      ],
      "metadata": {
        "id": "2KBP9WY5lja3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_csv = pd.DataFrame(y_pred, columns=['av_training_set'])"
      ],
      "metadata": {
        "id": "YuDhy1e7lyjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1qTc6kD3otYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = \"result_\" + unique_id + \".csv\""
      ],
      "metadata": {
        "id": "DEIt4m-Sojf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bP_-HKusorpX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}